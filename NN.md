线性模型：线性回归，线性分类（区别：输出连续的值，定义01离散，多一步非线性映射）
线性回归：g（xw+b）拟合数据
*股票预测：线性回归，多元线性回归（2-最小二乘法）（3-神经元学习算法：随机学习，梯度下降）*
最小二乘法最小均方误差 min(wx+b-y)求导=0推导/wb结论


神经网络的矩阵表示
多数入-一个神经元：三XW|=y|
多输入-多神经元：三WX|||=Y|||

MP神经元（wx，阈值函数，01）/感知机神经元（求和wx+b|f，不定）/FT神经元
输入输出
手工设计模型参数-正确输入输出
神经元自动学习参数-正确输入输出

MP 阈值函数/b01阶跃函数
and 112
or 111 
not -10
XR 相异为1相同为0 表达式/神经网络


3
输入输出-手工设计模型参数输入输出
神经元自动学习参数
神经元学习：有监督（过程描述）/无监督学习（潜在统计信息）
1）调整权重的方法：1.随机 2.hebb（•两个神经元之间的权值变换是与它们神经元的输出成比例的：βxy）3.梯度下降法（梯度，下降）(•梯度的方向就是函数之变化最快的方向)
*感知机有监督分类器/线性回归问题：Hebb学习 βxE(t-y)*
2）学习率调整方法（lr随时间/轮次t的二维变化）：1.学习率衰减（分段常数/逆时/指数/自然指数） 2.学习率预热 3.周期学习率 4.自适应学习率

梯度下降的问题：1.局部最小点（逃离局部最小点：多个初始点搜索/模拟退火思想以一定概率接受更差的结果） 2.学习率设置（学习率大小变化，不同参数相同学习率）

4
单个神经元学习拟合能力有限，多个神经元万能定理（

（网络需要考虑的问题）超参数：
模型：神经元种类/激活函数/个数/层数  
学习：初始化，损失函数，优化方法，学习率，循环控制（迭代次数+损失精度）
