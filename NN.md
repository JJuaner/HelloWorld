线性模型：线性回归，线性分类（区别：输出连续的值，定义01离散，多一步非线性映射）
线性回归：g（xw+b）拟合数据
*股票预测：线性回归，多元线性回归（2-最小二乘法）（3-神经元学习算法：随机学习，梯度下降）*
*水果二分类问题，多分类（多个神经元，输出onehot向量）*
最小二乘法最小均方误差 min(wx+b-y)求导=0推导/wb结论


神经网络的矩阵表示
多数入-一个神经元：三XW|=y|
多输入-多神经元：三WX|||=Y|||

MP神经元（wx，阈值函数，01）/感知机神经元（求和wx+b|f，不定）/FT神经元
输入输出
手工设计模型参数-正确输入输出
神经元自动学习参数-正确输入输出

注意输入输出01！！！！！！！
MP阈值函数/b01阶跃函数
and 112
or 111 
not -10
XR 相异为1相同为0 表达式<=>神经网络


3
输入输出-手工设计模型参数输入输出
神经元自动学习参数
神经元学习：有监督（过程描述）/无监督学习（潜在统计信息）
1）调整权重的方法：1.随机 2.hebb（•两个神经元之间的权值变换是与它们神经元的输出成比例的：βxy）3.梯度下降法（梯度，下降）(•梯度的方向就是函数之变化最快的方向)
*感知机有监督分类器/线性回归问题：Hebb学习 βxE(t-y)*
2）学习率调整方法（lr随时间/轮次t的二维变化）：1.学习率衰减（分段常数/逆时/指数/自然指数） 2.学习率预热 3.周期学习率 4.自适应学习率

梯度下降的问题：1.局部最小点（逃离局部最小点：不同初始化，多个初始点搜索/模拟退火思想以一定概率接受更差的结果/随机扰动遗传算法） 2.学习率设置（学习率大小变化，不同参数相同学习率）

4
单个神经元学习拟合能力有限，多个神经元万能定理：神经元的连接
层级结构（层内不连，层间全连接，感知机，BP）和互联网型（马尔科夫链：HN，BM）
CNN（本质：带有卷积计算的BP/结构/滑动窗口，权值共享）RNN（循环，反馈）
神经元的扩展：宽度（多维多输出单层感知机），深度（多层感知机，含有隐层，能力更强训练更难）
*多层感知机sinx的拟合：采样数据，手工搭建并设置单隐藏层网络模型（relu，逐点拟合）*密采样
多层感知机的训练：BP算法（梯度下降，链式法则反向传播）
单样本BP算法缺点：样本顺序敏感，
累计BP：收敛慢
动量BP



（网络需要考虑的问题，提高效果）超参数：
数据（密采样）模型复杂度
模型：神经元种类/激活函数/个数/层数  
学习：初始化，损失函数，优化方法，学习率，循环控制（迭代次数+损失精度）

•单层感知器无法应对非线性的问题，具有单隐层的神经网络可以拟合任意函数。
输入层（0层），输出层（层号=n级网络，Wj），隐藏层（隐藏层：除输入层和输出层以外的其它各层叫隐藏层。 隐藏层不直接接受外界的信号，也不直接向外界发送信号）

sigmoid：1/1+exp(-u) 导数：o(1-o) 图像


----------------------------------------------------------------------

MP神经元（wx，阈值函数，01）/感知机神经元（求和wx+b|f，不定）/FT神经元
输入输出
手工设计模型参数-正确输入输出
神经元自动学习参数-正确输入输出
注意输入输出01！！！！！！！
MP阈值函数/b01阶跃函数
and 112
or 111 
not -10
XR 相异为1相同为0 表达式<=>神经网络

训练过程/BP算法过程:
取样本
前向过程计算网络输出
计算误差
反向过程调整更新参数(梯度下降，链式法则反向传播)
net o 1/2(t-o)2
